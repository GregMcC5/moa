{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gregorymccollum/Documents/GitHub/moa/confirmed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import metadata_utils as mu\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Set Kernel\n",
    "if os.getcwd().split(\"/\")[-1] != \"confirmed\":\n",
    "        os.chdir(\"..\")\n",
    "        os.chdir(\"confirmed\")\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "confirmed = mu.read_csv(\"confirmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gregorymccollum/Documents/GitHub/moa/fuzzy_testing\n"
     ]
    }
   ],
   "source": [
    "#Moving Kernel\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] != \"fuzzy_testing\":\n",
    "    if os.getcwd().split(\"/\")[-1] == \"confirmed\":\n",
    "        os.chdir(\"..\")\n",
    "        os.chdir(\"fuzzy_testing\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now souping moaxml.nosync/moa1.xml\n",
      "now souping moaxml.nosync/moa2.xml\n",
      "now souping moaxml.nosync/moa3.xml\n",
      "now souping moaxml.nosync/moa4.xml\n",
      "now souping moaxml.nosync/moa5.xml\n",
      "now souping moaxml.nosync/moa6.xml\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "dlxs_ids = []\n",
    "\n",
    "for file in [f\"moaxml.nosync/moa{x}.xml\" for x in range(1,7)]:\n",
    "    soup_file = open(file)\n",
    "    print(f\"now souping {file}\")\n",
    "    soup = BeautifulSoup(soup_file, features=\"xml\")\n",
    "    for entry in soup.find_all(\"DLPSTEXTCLASS\"):\n",
    "        dlxs_ids.append(entry.find(\"IDNO\").text)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['AAB2140.0001.001', 'AEV8795.0001.001', 'AAT2305.0001.001', 'AJL7593.0001.001']\n"
     ]
    }
   ],
   "source": [
    "missing_ids = [x for x in dlxs_ids if x not in [x[1] for x in confirmed]]\n",
    "print(len(missing_ids))\n",
    "print(missing_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gregorymccollum/Documents/GitHub/moa/confirmed\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import metadata_utils as mu\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] != \"confirmed\":\n",
    "        os.chdir(\"..\")\n",
    "        os.chdir(\"confirmed\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dlxs_data = mu.read_json(\"dlxs_moa_extracted.json\")\n",
    "matche = mu.read_csv(\"id_key_test.csv\")\n",
    "new_sheet = []\n",
    "\n",
    "\n",
    "for id in missing_ids:\n",
    "    try:\n",
    "        mms_match = [x[2] for x in matche if x[0] == id][0]\n",
    "    except:\n",
    "        print(\"no mms match for:\", id)\n",
    "    try:\n",
    "        data = [entry for entry in dlxs_data if entry[\"id\"] == id][0]\n",
    "    except:\n",
    "        print(\"no dlxs match for:\", id)\n",
    "    hathi_link = f\"https://babel.hathitrust.org/cgi/pt?id=miun.{id.lower()}\"\n",
    "    search_links = f\"https://search.lib.umich.edu/catalog?library=All+libraries&query={urllib.parse.quote(data['title'])}\"\n",
    "    dlxs_link = f\"https://quod.lib.umich.edu/m/moa/{id}/\"\n",
    "    new_sheet.append([\" \"] + [hathi_link] + [dlxs_link] + [search_links] + [mms_match] + [val for val in data.values()])\n",
    "\n",
    "mu.write_csv(\"new_r3_missings.csv\", new_sheet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
